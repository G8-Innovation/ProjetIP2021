{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date :** Created on Tuesday January 12 2021  \n",
    "\n",
    "**Group 8 - Innovation**\n",
    "\n",
    "**queries_simulation_v0** \n",
    "\n",
    "**@author :** Damien Sonneville. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description :** Simulation of requests for improvement of our models from scrapping data  art_tag and management and innovation keywords provided by the client.\n",
    "\n",
    "- On the `art_tag` simulation of requests in 3 different ways:\n",
    "\n",
    "> - `Naïve`: list without duplicates of all tags\n",
    "> - `Random`: random draw without replacement on all the words present in the tags \n",
    "> - `By weight`: draw with the weight of each word in the tags with a maximum number of 10 repetitions of a word in the queries.\n",
    "\n",
    "- On the `keywords`:\n",
    "\n",
    "> - Random selection of N words with a maximum number of repetitions of a word in queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Install / Download / Import Librairy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Librairy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Boulanger\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Boulanger\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import librairy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Usefull librairy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pickle\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Text librairy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_data(helper_path : str) -> pd.DataFrame:\n",
    "    \"\"\"Documentation\n",
    "    \n",
    "    Parameters :\n",
    "        - helper_path : the file path\n",
    "\n",
    "    Output (if exists) :\n",
    "        - df : My Dataframe cleaned and reindexed\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Data Load with pandas librairy\n",
    "    df = pd.read_json(helper_path)\n",
    "\n",
    "    # Drop articles with no content\n",
    "    df = df[df['art_content'] != '']\n",
    "\n",
    "    # Reset my dataframe index\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    # Returns my clean dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Pickle(helper_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Documentation\n",
    "    \n",
    "    Parameters :\n",
    "        - helper_path : the file path\n",
    "\n",
    "    Output (if exists) :\n",
    "        - pick_file : My pickle file\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Open My file path\n",
    "    with open(helper_path, 'rb') as f1:\n",
    "\n",
    "        # Load Pickle file\n",
    "        pick_file = pickle.load(f1)\n",
    "\n",
    "        # Return Pickle file\n",
    "        return pick_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Phase 1 :** Load json Data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_id</th>\n",
       "      <th>art_content</th>\n",
       "      <th>art_content_html</th>\n",
       "      <th>art_extract_datetime</th>\n",
       "      <th>art_lang</th>\n",
       "      <th>art_title</th>\n",
       "      <th>art_url</th>\n",
       "      <th>src_name</th>\n",
       "      <th>src_type</th>\n",
       "      <th>src_url</th>\n",
       "      <th>src_img</th>\n",
       "      <th>art_auth</th>\n",
       "      <th>art_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>La FNCDG et l’ANDCDG ont publié en septembre l...</td>\n",
       "      <td>&lt;p style=\"text-align: justify;\"&gt;La FNCDG et l’...</td>\n",
       "      <td>22 septembre 2020</td>\n",
       "      <td>fr</td>\n",
       "      <td>9ème édition du Panorama de l’emploi territorial</td>\n",
       "      <td>http://fncdg.com/9eme-edition-du-panorama-de-l...</td>\n",
       "      <td>FNCDG</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>http://fncdg.com/actualites/</td>\n",
       "      <td>http://fncdg.com/wp-content/uploads/2020/09/im...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Malgré la levée des mesures de confinement le ...</td>\n",
       "      <td>&lt;p style=\"text-align: justify;\"&gt;Malgré la levé...</td>\n",
       "      <td>17 mars 2020</td>\n",
       "      <td>fr</td>\n",
       "      <td>ACTUALITÉS FNCDG / COVID19</td>\n",
       "      <td>http://fncdg.com/actualites-covid19/</td>\n",
       "      <td>FNCDG</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>http://fncdg.com/actualites/</td>\n",
       "      <td>http://fncdg.com/wp-content/uploads/2020/03/co...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>Quels étaient les objectifs poursuivis par le ...</td>\n",
       "      <td>&lt;p style=\"text-align: justify;\"&gt;&lt;strong&gt;Quels ...</td>\n",
       "      <td>24 octobre 2019</td>\n",
       "      <td>fr</td>\n",
       "      <td>Interview de M. Olivier DUSSOPT, Secretaire d’...</td>\n",
       "      <td>http://fncdg.com/interview-de-m-olivier-dussop...</td>\n",
       "      <td>FNCDG</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>http://fncdg.com/actualites/</td>\n",
       "      <td>http://fncdg.com/wp-content/uploads/2019/10/in...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>La journée thématique, qui aura lieu durant le...</td>\n",
       "      <td>&lt;p style=\"text-align: justify;\"&gt;&lt;strong&gt;La  jo...</td>\n",
       "      <td>31 mai 2017</td>\n",
       "      <td>fr</td>\n",
       "      <td>Journée Thématique FNCDG « Les services de san...</td>\n",
       "      <td>http://fncdg.com/journee-thematique-fncdg-les-...</td>\n",
       "      <td>FNCDG</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>http://fncdg.com/actualites/</td>\n",
       "      <td>http://fncdg.com/wp-content/uploads/2017/05/pu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>La 1ère journée thématique en région sur le th...</td>\n",
       "      <td>&lt;p style=\"text-align: justify;\"&gt;La 1&lt;sup&gt;ère&lt;/...</td>\n",
       "      <td>13 mars 2017</td>\n",
       "      <td>fr</td>\n",
       "      <td>Journée Thématique FNCDG « Vers de nouveaux mo...</td>\n",
       "      <td>http://fncdg.com/journee-thematique-fncdg-vers...</td>\n",
       "      <td>FNCDG</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>http://fncdg.com/actualites/</td>\n",
       "      <td>http://fncdg.com/wp-content/uploads/2017/03/Sa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>L’une des innovations de la loi n°2019-828 du ...</td>\n",
       "      <td>&lt;p style=\"text-align: justify;\"&gt;L’une des inno...</td>\n",
       "      <td>22 octobre 2020</td>\n",
       "      <td>fr</td>\n",
       "      <td>La publication d’un guide d’accompagnement à l...</td>\n",
       "      <td>http://fncdg.com/la-publication-dun-guide-dacc...</td>\n",
       "      <td>FNCDG</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>http://fncdg.com/actualites/</td>\n",
       "      <td>http://fncdg.com/wp-content/uploads/2020/10/LG...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>La FNCDG mène, en collaboration avec d’autres ...</td>\n",
       "      <td>&lt;p style=\"text-align: justify;\"&gt;La FNCDG mène,...</td>\n",
       "      <td>10 décembre 2020</td>\n",
       "      <td>fr</td>\n",
       "      <td>La publication d’un guide de sensibilisation a...</td>\n",
       "      <td>http://fncdg.com/la-publication-dun-guide-de-s...</td>\n",
       "      <td>FNCDG</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>http://fncdg.com/actualites/</td>\n",
       "      <td>http://fncdg.com/wp-content/uploads/2020/12/im...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>Créé pour et par les décideurs territoriaux, É...</td>\n",
       "      <td>&lt;p style=\"text-align: justify;\"&gt;Créé pour et p...</td>\n",
       "      <td>24 février 2017</td>\n",
       "      <td>fr</td>\n",
       "      <td>Lancement du réseau Étoile</td>\n",
       "      <td>http://fncdg.com/lancement-du-reseau-etoile/</td>\n",
       "      <td>FNCDG</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>http://fncdg.com/actualites/</td>\n",
       "      <td>http://fncdg.com/wp-content/uploads/2017/02/re...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>Les décrets n°2017-397 et n°2017-318 du 24 mar...</td>\n",
       "      <td>&lt;p style=\"text-align: justify;\"&gt;Les décrets n°...</td>\n",
       "      <td>5 avril 2017</td>\n",
       "      <td>fr</td>\n",
       "      <td>Le cadre d’emplois des agents de police munici...</td>\n",
       "      <td>http://fncdg.com/le-cadre-demplois-des-agents-...</td>\n",
       "      <td>FNCDG</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>http://fncdg.com/actualites/</td>\n",
       "      <td>http://fncdg.com/wp-content/uploads/2017/04/po...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35</td>\n",
       "      <td>Une candidate à un examen professionnel organi...</td>\n",
       "      <td>&lt;p style=\"text-align: justify;\"&gt;Une candidate ...</td>\n",
       "      <td>6 juillet 2017</td>\n",
       "      <td>fr</td>\n",
       "      <td>Le Conseil d’Etat confirme la souveraineté des...</td>\n",
       "      <td>http://fncdg.com/le-conseil-detat-confirme-la-...</td>\n",
       "      <td>FNCDG</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>http://fncdg.com/actualites/</td>\n",
       "      <td>http://fncdg.com/wp-content/uploads/2017/07/Co...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   art_id                                        art_content  \\\n",
       "0       1  La FNCDG et l’ANDCDG ont publié en septembre l...   \n",
       "1       2  Malgré la levée des mesures de confinement le ...   \n",
       "2      25  Quels étaient les objectifs poursuivis par le ...   \n",
       "3      27  La journée thématique, qui aura lieu durant le...   \n",
       "4      28  La 1ère journée thématique en région sur le th...   \n",
       "5      30  L’une des innovations de la loi n°2019-828 du ...   \n",
       "6      31  La FNCDG mène, en collaboration avec d’autres ...   \n",
       "7      32  Créé pour et par les décideurs territoriaux, É...   \n",
       "8      34  Les décrets n°2017-397 et n°2017-318 du 24 mar...   \n",
       "9      35  Une candidate à un examen professionnel organi...   \n",
       "\n",
       "                                    art_content_html art_extract_datetime  \\\n",
       "0  <p style=\"text-align: justify;\">La FNCDG et l’...    22 septembre 2020   \n",
       "1  <p style=\"text-align: justify;\">Malgré la levé...         17 mars 2020   \n",
       "2  <p style=\"text-align: justify;\"><strong>Quels ...      24 octobre 2019   \n",
       "3  <p style=\"text-align: justify;\"><strong>La  jo...          31 mai 2017   \n",
       "4  <p style=\"text-align: justify;\">La 1<sup>ère</...         13 mars 2017   \n",
       "5  <p style=\"text-align: justify;\">L’une des inno...      22 octobre 2020   \n",
       "6  <p style=\"text-align: justify;\">La FNCDG mène,...     10 décembre 2020   \n",
       "7  <p style=\"text-align: justify;\">Créé pour et p...      24 février 2017   \n",
       "8  <p style=\"text-align: justify;\">Les décrets n°...         5 avril 2017   \n",
       "9  <p style=\"text-align: justify;\">Une candidate ...       6 juillet 2017   \n",
       "\n",
       "  art_lang                                          art_title  \\\n",
       "0       fr   9ème édition du Panorama de l’emploi territorial   \n",
       "1       fr                         ACTUALITÉS FNCDG / COVID19   \n",
       "2       fr  Interview de M. Olivier DUSSOPT, Secretaire d’...   \n",
       "3       fr  Journée Thématique FNCDG « Les services de san...   \n",
       "4       fr  Journée Thématique FNCDG « Vers de nouveaux mo...   \n",
       "5       fr  La publication d’un guide d’accompagnement à l...   \n",
       "6       fr  La publication d’un guide de sensibilisation a...   \n",
       "7       fr                         Lancement du réseau Étoile   \n",
       "8       fr  Le cadre d’emplois des agents de police munici...   \n",
       "9       fr  Le Conseil d’Etat confirme la souveraineté des...   \n",
       "\n",
       "                                             art_url src_name      src_type  \\\n",
       "0  http://fncdg.com/9eme-edition-du-panorama-de-l...    FNCDG  xpath_source   \n",
       "1               http://fncdg.com/actualites-covid19/    FNCDG  xpath_source   \n",
       "2  http://fncdg.com/interview-de-m-olivier-dussop...    FNCDG  xpath_source   \n",
       "3  http://fncdg.com/journee-thematique-fncdg-les-...    FNCDG  xpath_source   \n",
       "4  http://fncdg.com/journee-thematique-fncdg-vers...    FNCDG  xpath_source   \n",
       "5  http://fncdg.com/la-publication-dun-guide-dacc...    FNCDG  xpath_source   \n",
       "6  http://fncdg.com/la-publication-dun-guide-de-s...    FNCDG  xpath_source   \n",
       "7       http://fncdg.com/lancement-du-reseau-etoile/    FNCDG  xpath_source   \n",
       "8  http://fncdg.com/le-cadre-demplois-des-agents-...    FNCDG  xpath_source   \n",
       "9  http://fncdg.com/le-conseil-detat-confirme-la-...    FNCDG  xpath_source   \n",
       "\n",
       "                        src_url  \\\n",
       "0  http://fncdg.com/actualites/   \n",
       "1  http://fncdg.com/actualites/   \n",
       "2  http://fncdg.com/actualites/   \n",
       "3  http://fncdg.com/actualites/   \n",
       "4  http://fncdg.com/actualites/   \n",
       "5  http://fncdg.com/actualites/   \n",
       "6  http://fncdg.com/actualites/   \n",
       "7  http://fncdg.com/actualites/   \n",
       "8  http://fncdg.com/actualites/   \n",
       "9  http://fncdg.com/actualites/   \n",
       "\n",
       "                                             src_img art_auth art_tag  \n",
       "0  http://fncdg.com/wp-content/uploads/2020/09/im...     None    None  \n",
       "1  http://fncdg.com/wp-content/uploads/2020/03/co...     None    None  \n",
       "2  http://fncdg.com/wp-content/uploads/2019/10/in...     None    None  \n",
       "3  http://fncdg.com/wp-content/uploads/2017/05/pu...     None    None  \n",
       "4  http://fncdg.com/wp-content/uploads/2017/03/Sa...     None    None  \n",
       "5  http://fncdg.com/wp-content/uploads/2020/10/LG...     None    None  \n",
       "6  http://fncdg.com/wp-content/uploads/2020/12/im...     None    None  \n",
       "7  http://fncdg.com/wp-content/uploads/2017/02/re...     None    None  \n",
       "8  http://fncdg.com/wp-content/uploads/2017/04/po...     None    None  \n",
       "9  http://fncdg.com/wp-content/uploads/2017/07/Co...     None    None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My file path for the fonction\n",
    "Helper_path_F : str = 'C:/Users/Boulanger/Documents/interpromo_2021/df_deduplicated_v4.json'\n",
    "\n",
    "# My DataFrame variable\n",
    "First_data : pd.DataFrame = Load_data(Helper_path_F)\n",
    "\n",
    "# To show my DataFrame\n",
    "First_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_content_html</th>\n",
       "      <th>art_content</th>\n",
       "      <th>art_published_datetime</th>\n",
       "      <th>art_lang</th>\n",
       "      <th>art_title</th>\n",
       "      <th>art_url</th>\n",
       "      <th>src_name</th>\n",
       "      <th>src_type</th>\n",
       "      <th>src_url</th>\n",
       "      <th>art_img</th>\n",
       "      <th>art_auth</th>\n",
       "      <th>art_tag</th>\n",
       "      <th>art_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;article class=\"contenuArticle\" itemscope=\"\" i...</td>\n",
       "      <td>\\n\\n\\nNiantic acquiert la start-up 6D.ai, spéc...</td>\n",
       "      <td>1585612800000</td>\n",
       "      <td>fr_FR</td>\n",
       "      <td>Niantic acquiert la start-up 6D.ai, spécialist...</td>\n",
       "      <td>https://www.usine-digitale.fr/article/niantic-...</td>\n",
       "      <td>L'Usine Digitale</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>usine-digitale.fr</td>\n",
       "      <td>https://www.usine-digitale.fr/mediatheque/6/1/...</td>\n",
       "      <td>[Arthur Le Denn]</td>\n",
       "      <td>['Acquisition', 'Réalité augmentée', 'Start-up']</td>\n",
       "      <td>g2_1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;article class=\"contenuArticle\" itemscope=\"\" i...</td>\n",
       "      <td>\\n\\n\\nNiantic lève 245 millions de dollars pou...</td>\n",
       "      <td>1548028800000</td>\n",
       "      <td>fr_FR</td>\n",
       "      <td>Niantic lève 245 millions de dollars pour déve...</td>\n",
       "      <td>https://www.usine-digitale.fr/article/niantic-...</td>\n",
       "      <td>L'Usine Digitale</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>usine-digitale.fr</td>\n",
       "      <td>https://www.usine-digitale.fr/mediatheque/5/5/...</td>\n",
       "      <td>[Julien Bergounhoux]</td>\n",
       "      <td>['Réalité augmentée', 'Start-up', 'Innovation']</td>\n",
       "      <td>g2_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;article class=\"contenuArticle\" itemscope=\"\" i...</td>\n",
       "      <td>\\n\\n\\nTwitch, Mixer, YouTube... La guerre du s...</td>\n",
       "      <td>1574294400000</td>\n",
       "      <td>fr_FR</td>\n",
       "      <td>Twitch, Mixer, YouTube... La guerre du streami...</td>\n",
       "      <td>https://www.usine-digitale.fr/article/twitch-m...</td>\n",
       "      <td>L'Usine Digitale</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>usine-digitale.fr</td>\n",
       "      <td>https://www.usine-digitale.fr/mediatheque/9/6/...</td>\n",
       "      <td>[Fabrice Deblock]</td>\n",
       "      <td>['Jeux Video', 'Streaming', 'Twitch']</td>\n",
       "      <td>g2_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;article class=\"contenuArticle\" itemscope=\"\" i...</td>\n",
       "      <td>\\n\\n\\nL'Armée française utilisera les drones d...</td>\n",
       "      <td>1610409600000</td>\n",
       "      <td>fr_FR</td>\n",
       "      <td>L'Armée française utilisera les drones de Parr...</td>\n",
       "      <td>https://www.usine-digitale.fr/article/l-armee-...</td>\n",
       "      <td>L'Usine Digitale</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>usine-digitale.fr</td>\n",
       "      <td>https://www.usine-digitale.fr/mediatheque/4/4/...</td>\n",
       "      <td>[Alice Vitard]</td>\n",
       "      <td>['Drone', 'Aéronautique - Spatial', 'Parrot']</td>\n",
       "      <td>g2_1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;article class=\"contenuArticle\" itemscope=\"\" i...</td>\n",
       "      <td>\\n\\n\\nAlibaba et Ant Group pourraient être nat...</td>\n",
       "      <td>1610409600000</td>\n",
       "      <td>fr_FR</td>\n",
       "      <td>Alibaba et Ant Group pourraient être nationali...</td>\n",
       "      <td>https://www.usine-digitale.fr/article/alibaba-...</td>\n",
       "      <td>L'Usine Digitale</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>usine-digitale.fr</td>\n",
       "      <td>https://www.usine-digitale.fr/mediatheque/4/5/...</td>\n",
       "      <td>[Aude Chardenon]</td>\n",
       "      <td>['Politique', 'Digital Retail', 'e-commerce']</td>\n",
       "      <td>g2_1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;article class=\"contenuArticle\" itemscope=\"\" i...</td>\n",
       "      <td>\\n\\n\\n[CES 2021] Sony a débuté les tests sur r...</td>\n",
       "      <td>1610409600000</td>\n",
       "      <td>fr_FR</td>\n",
       "      <td>[CES 2021] Sony a débuté les tests sur route d...</td>\n",
       "      <td>https://www.usine-digitale.fr/article/ces-2021...</td>\n",
       "      <td>L'Usine Digitale</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>usine-digitale.fr</td>\n",
       "      <td>https://www.usine-digitale.fr/mediatheque/4/5/...</td>\n",
       "      <td>[Léna Corot]</td>\n",
       "      <td>['Automobile', 'CES 2021', 'Mobilité']</td>\n",
       "      <td>g2_1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;article class=\"contenuArticle\" itemscope=\"\" i...</td>\n",
       "      <td>\\n\\n\\nGetfluence lève 5 millions d'euros pour ...</td>\n",
       "      <td>1610409600000</td>\n",
       "      <td>fr_FR</td>\n",
       "      <td>Getfluence lève 5 millions d'euros pour étendr...</td>\n",
       "      <td>https://www.usine-digitale.fr/article/getfluen...</td>\n",
       "      <td>L'Usine Digitale</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>usine-digitale.fr</td>\n",
       "      <td>https://www.usine-digitale.fr/mediatheque/9/0/...</td>\n",
       "      <td>[Aude Chardenon]</td>\n",
       "      <td>['Start-up', 'Marketing', 'French Tech']</td>\n",
       "      <td>g2_1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;article class=\"contenuArticle\" itemscope=\"\" i...</td>\n",
       "      <td>\\n\\n\\nRoblox lève 520 millions de dollars, sa ...</td>\n",
       "      <td>1609977600000</td>\n",
       "      <td>fr_FR</td>\n",
       "      <td>Roblox lève 520 millions de dollars, sa valori...</td>\n",
       "      <td>https://www.usine-digitale.fr/article/roblox-l...</td>\n",
       "      <td>L'Usine Digitale</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>usine-digitale.fr</td>\n",
       "      <td>https://www.usine-digitale.fr/mediatheque/4/8/...</td>\n",
       "      <td>[Aude Chardenon]</td>\n",
       "      <td>['Jeux Video', 'Start-up', 'Financement']</td>\n",
       "      <td>g2_1_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;article class=\"contenuArticle\" itemscope=\"\" i...</td>\n",
       "      <td>\\n\\n\\nNintendo va acquérir le studio canadien ...</td>\n",
       "      <td>1609804800000</td>\n",
       "      <td>fr_FR</td>\n",
       "      <td>Nintendo va acquérir le studio canadien Next L...</td>\n",
       "      <td>https://www.usine-digitale.fr/article/nintendo...</td>\n",
       "      <td>L'Usine Digitale</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>usine-digitale.fr</td>\n",
       "      <td>https://www.usine-digitale.fr/mediatheque/4/5/...</td>\n",
       "      <td>[Aude Chardenon]</td>\n",
       "      <td>['Acquisition', 'Nintendo', 'Jeux Video']</td>\n",
       "      <td>g2_1_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;article class=\"contenuArticle\" itemscope=\"\" i...</td>\n",
       "      <td>\\n\\n\\nGoogle et Disney animent les personnages...</td>\n",
       "      <td>1606176000000</td>\n",
       "      <td>fr_FR</td>\n",
       "      <td>Google et Disney animent les personnages de Th...</td>\n",
       "      <td>https://www.usine-digitale.fr/article/google-l...</td>\n",
       "      <td>L'Usine Digitale</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>usine-digitale.fr</td>\n",
       "      <td>https://www.usine-digitale.fr/mediatheque/4/8/...</td>\n",
       "      <td>[Aude Chardenon]</td>\n",
       "      <td>['Réalité augmentée', 'Entertainment', 'Loisir...</td>\n",
       "      <td>g2_1_9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    art_content_html  \\\n",
       "0  <article class=\"contenuArticle\" itemscope=\"\" i...   \n",
       "1  <article class=\"contenuArticle\" itemscope=\"\" i...   \n",
       "2  <article class=\"contenuArticle\" itemscope=\"\" i...   \n",
       "3  <article class=\"contenuArticle\" itemscope=\"\" i...   \n",
       "4  <article class=\"contenuArticle\" itemscope=\"\" i...   \n",
       "5  <article class=\"contenuArticle\" itemscope=\"\" i...   \n",
       "6  <article class=\"contenuArticle\" itemscope=\"\" i...   \n",
       "7  <article class=\"contenuArticle\" itemscope=\"\" i...   \n",
       "8  <article class=\"contenuArticle\" itemscope=\"\" i...   \n",
       "9  <article class=\"contenuArticle\" itemscope=\"\" i...   \n",
       "\n",
       "                                         art_content  art_published_datetime  \\\n",
       "0  \\n\\n\\nNiantic acquiert la start-up 6D.ai, spéc...           1585612800000   \n",
       "1  \\n\\n\\nNiantic lève 245 millions de dollars pou...           1548028800000   \n",
       "2  \\n\\n\\nTwitch, Mixer, YouTube... La guerre du s...           1574294400000   \n",
       "3  \\n\\n\\nL'Armée française utilisera les drones d...           1610409600000   \n",
       "4  \\n\\n\\nAlibaba et Ant Group pourraient être nat...           1610409600000   \n",
       "5  \\n\\n\\n[CES 2021] Sony a débuté les tests sur r...           1610409600000   \n",
       "6  \\n\\n\\nGetfluence lève 5 millions d'euros pour ...           1610409600000   \n",
       "7  \\n\\n\\nRoblox lève 520 millions de dollars, sa ...           1609977600000   \n",
       "8  \\n\\n\\nNintendo va acquérir le studio canadien ...           1609804800000   \n",
       "9  \\n\\n\\nGoogle et Disney animent les personnages...           1606176000000   \n",
       "\n",
       "  art_lang                                          art_title  \\\n",
       "0    fr_FR  Niantic acquiert la start-up 6D.ai, spécialist...   \n",
       "1    fr_FR  Niantic lève 245 millions de dollars pour déve...   \n",
       "2    fr_FR  Twitch, Mixer, YouTube... La guerre du streami...   \n",
       "3    fr_FR  L'Armée française utilisera les drones de Parr...   \n",
       "4    fr_FR  Alibaba et Ant Group pourraient être nationali...   \n",
       "5    fr_FR  [CES 2021] Sony a débuté les tests sur route d...   \n",
       "6    fr_FR  Getfluence lève 5 millions d'euros pour étendr...   \n",
       "7    fr_FR  Roblox lève 520 millions de dollars, sa valori...   \n",
       "8    fr_FR  Nintendo va acquérir le studio canadien Next L...   \n",
       "9    fr_FR  Google et Disney animent les personnages de Th...   \n",
       "\n",
       "                                             art_url          src_name  \\\n",
       "0  https://www.usine-digitale.fr/article/niantic-...  L'Usine Digitale   \n",
       "1  https://www.usine-digitale.fr/article/niantic-...  L'Usine Digitale   \n",
       "2  https://www.usine-digitale.fr/article/twitch-m...  L'Usine Digitale   \n",
       "3  https://www.usine-digitale.fr/article/l-armee-...  L'Usine Digitale   \n",
       "4  https://www.usine-digitale.fr/article/alibaba-...  L'Usine Digitale   \n",
       "5  https://www.usine-digitale.fr/article/ces-2021...  L'Usine Digitale   \n",
       "6  https://www.usine-digitale.fr/article/getfluen...  L'Usine Digitale   \n",
       "7  https://www.usine-digitale.fr/article/roblox-l...  L'Usine Digitale   \n",
       "8  https://www.usine-digitale.fr/article/nintendo...  L'Usine Digitale   \n",
       "9  https://www.usine-digitale.fr/article/google-l...  L'Usine Digitale   \n",
       "\n",
       "       src_type            src_url  \\\n",
       "0  xpath_source  usine-digitale.fr   \n",
       "1  xpath_source  usine-digitale.fr   \n",
       "2  xpath_source  usine-digitale.fr   \n",
       "3  xpath_source  usine-digitale.fr   \n",
       "4  xpath_source  usine-digitale.fr   \n",
       "5  xpath_source  usine-digitale.fr   \n",
       "6  xpath_source  usine-digitale.fr   \n",
       "7  xpath_source  usine-digitale.fr   \n",
       "8  xpath_source  usine-digitale.fr   \n",
       "9  xpath_source  usine-digitale.fr   \n",
       "\n",
       "                                             art_img              art_auth  \\\n",
       "0  https://www.usine-digitale.fr/mediatheque/6/1/...      [Arthur Le Denn]   \n",
       "1  https://www.usine-digitale.fr/mediatheque/5/5/...  [Julien Bergounhoux]   \n",
       "2  https://www.usine-digitale.fr/mediatheque/9/6/...     [Fabrice Deblock]   \n",
       "3  https://www.usine-digitale.fr/mediatheque/4/4/...        [Alice Vitard]   \n",
       "4  https://www.usine-digitale.fr/mediatheque/4/5/...      [Aude Chardenon]   \n",
       "5  https://www.usine-digitale.fr/mediatheque/4/5/...          [Léna Corot]   \n",
       "6  https://www.usine-digitale.fr/mediatheque/9/0/...      [Aude Chardenon]   \n",
       "7  https://www.usine-digitale.fr/mediatheque/4/8/...      [Aude Chardenon]   \n",
       "8  https://www.usine-digitale.fr/mediatheque/4/5/...      [Aude Chardenon]   \n",
       "9  https://www.usine-digitale.fr/mediatheque/4/8/...      [Aude Chardenon]   \n",
       "\n",
       "                                             art_tag  art_id  \n",
       "0   ['Acquisition', 'Réalité augmentée', 'Start-up']  g2_1_0  \n",
       "1    ['Réalité augmentée', 'Start-up', 'Innovation']  g2_1_1  \n",
       "2              ['Jeux Video', 'Streaming', 'Twitch']  g2_1_2  \n",
       "3      ['Drone', 'Aéronautique - Spatial', 'Parrot']  g2_1_3  \n",
       "4      ['Politique', 'Digital Retail', 'e-commerce']  g2_1_4  \n",
       "5             ['Automobile', 'CES 2021', 'Mobilité']  g2_1_5  \n",
       "6           ['Start-up', 'Marketing', 'French Tech']  g2_1_6  \n",
       "7          ['Jeux Video', 'Start-up', 'Financement']  g2_1_7  \n",
       "8          ['Acquisition', 'Nintendo', 'Jeux Video']  g2_1_8  \n",
       "9  ['Réalité augmentée', 'Entertainment', 'Loisir...  g2_1_9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My file path for the fonction\n",
    "Helper_path_S : str = 'C:/Users/Boulanger/Documents/interpromo_2021/usines-digitale.json'\n",
    "\n",
    "# My DataFrame variable\n",
    "Second_data : pd.DataFrame = Load_data(Helper_path_S,)\n",
    "\n",
    "# Change type column\n",
    "Second_data['art_tag'] : pd.DataFrame = Second_data['art_tag'].astype(str)\n",
    "    \n",
    "# To show my DataFrame\n",
    "Second_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Phase 2 :** Load Pickle Data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My file path for the fonction\n",
    "Helper_path_FP : str = 'C:/Users\\Boulanger/Documents/interpromo_2021/pickle_files/liste_mots_cles_innovation.p'\n",
    "\n",
    "# My file path for the fonction\n",
    "Helper_path_SP : str = 'C:/Users\\Boulanger/Documents/interpromo_2021/pickle_files/liste_mots_cles_gestion.p'\n",
    "    \n",
    "# Load Keywords Pickle\n",
    "List_keywords : list = Load_Pickle(Helper_path_FP)\n",
    "\n",
    "# Extend Keywords Pickle\n",
    "List_keywords.extend(Load_Pickle(Helper_path_SP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cleanning(item: str, special_character : list) -> str :\n",
    "    \"\"\"Documentation\n",
    "    \n",
    "    Parameters :\n",
    "        - item: all articles without the removal of unnecessary words\n",
    "        (for example : \"stopWords\") in the column [\"art_content\"]\n",
    "        - special_character: a list of specials characters to \n",
    "        remove to the articles in the column [\"art_content\"]\n",
    "\n",
    "    Output (if exists) :\n",
    "        - result: all articles without unnecessary words \n",
    "        and characters \n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    item : str = item.lower()\n",
    "\n",
    "    # Remove mail\n",
    "    item : str = re.sub(\"(\\w+)@(\\w+).(\\w+)\",\"\",item)\n",
    "\n",
    "    # Remove twitter name\n",
    "    item : str = re.sub(\"@(\\w+)\",\"\",item)\n",
    "\n",
    "    # Remove site \".com\"\n",
    "    item : str = re.sub(\"(\\S+).com(\\S+)\",\"\",item)\n",
    "    item : str = re.sub(\"(\\S+).com\",\"\",item)\n",
    "        \n",
    "    # Remove site \".fr\"   \n",
    "    item : str = re.sub(\"(\\S+).fr(\\S+)\",\"\",item)\n",
    "    item : str = re.sub(\"(\\S+).fr\",\"\",item)\n",
    "\n",
    "    # Remove numbers\n",
    "    # item : str = re.sub(r'\\d+', '', item)\n",
    "\n",
    "    # Remove hastags\n",
    "    item : str = re.sub(\"#(\\w+)\",\"\",item)\n",
    "\n",
    "    # Remove years\n",
    "    # item : str = re.sub(\"en (\\d+)\",\"\",item)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    item : str = item.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Step 1 : Remove French accents\n",
    "    for i in range(len(item)):\n",
    "    \n",
    "        # Get the article\n",
    "        try:\n",
    "        \n",
    "            # Transform to 'utf-8'\n",
    "            item = unicode(item , 'utf-8')\n",
    "    \n",
    "        except NameError: # unicode is a default on python 3 \n",
    "        \n",
    "            pass\n",
    "        \n",
    "        # Remove the accents\n",
    "        item = unicodedata.normalize('NFD', str(item)) \\\n",
    "                            .encode('ascii', 'ignore') \\\n",
    "                            .decode(\"utf-8\")\n",
    "    \n",
    "    # Step 2 : Remove Special character \n",
    "    for i in special_character:\n",
    "        \n",
    "        item = item.replace(i, \"\")\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(nltk.corpus.stopwords.words('french'))\n",
    "    tokens = word_tokenize(item)\n",
    "    result = [i for i in tokens if not i in stop_words]\n",
    "    result = \" \".join(result)\n",
    "    \n",
    "    # Remove whitespaces\n",
    "    result = result.strip()\n",
    "    \n",
    "    # Return my cleaned article\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_column(data: pd.DataFrame, name_column: str, spe_charact : list) -> pd.DataFrame:\n",
    "    \"\"\"Documentation\n",
    "    \n",
    "    Parameters :\n",
    "        - data: DataFrame containing the column we want to clean\n",
    "        - name_column: name of the column to clean\n",
    "\n",
    "    Output (if exists) :\n",
    "        - df: My Dataframe cleaned and reindexed\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Selected column for clean\n",
    "    df: pd.DataFrame = data[[name_column]]\n",
    "    \n",
    "    # My initialized column\n",
    "    df['clean']: pd.DataFrame = ''\n",
    "    \n",
    "    # Remove missing data\n",
    "    df: pd.DataFrame = df.dropna()\n",
    "    \n",
    "    # Reset index DataFrame\n",
    "    df: pd.DataFrame = df.reset_index(drop = True)\n",
    "    \n",
    "    # Step 1 : Cleanning each rows\n",
    "    for i in trange(len(df), position=0, leave=True):\n",
    "        \n",
    "        # Call Cleanning functiion\n",
    "        df.loc[i, 'clean'] = Cleanning(df.loc[i, name_column], \\\n",
    "                                       Special_character)\n",
    "\n",
    "    # Remove NaN data\n",
    "    df[\"clean\"]: pd.DataFrame = df[\"clean\"].replace(\"\", np.NaN)\n",
    "    \n",
    "    # Remove missing data\n",
    "    df: pd.DataFrame = df.dropna()\n",
    "    \n",
    "    # Reset index DataFrame\n",
    "    df: pd.DataFrame = df.reset_index(drop=True)\n",
    "    \n",
    "    # Return my clean column\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Boulanger\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6185/6185 [00:06<00:00, 1000.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1602/1602 [00:01<00:00, 1074.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create my list of special characters\n",
    "Special_character: list = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"\\\\\", \"(\", \\\n",
    "                           \")\", \"*\", \"+\", \",\", \"-\", \".\", \"/\", \":\", \";\", \\\n",
    "                           \"<\", \"=\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \\\n",
    "                           \"{\", \"|\", \"}\", \"~\", \"«\", \"»\", \"’\", \"•\", \"…\", \\\n",
    "                           \"â\", \"€\", \"™\", \"—\", \"�\", \"–\", \"“\", \"”\"]\n",
    "    \n",
    "\n",
    "# Cleanning my column \n",
    "First_df_tag : pd.DataFrame = Clean_column(First_data, 'art_tag', Special_character)\n",
    "    \n",
    "# Cleanning my column \n",
    "Second_df_tag : pd.DataFrame = Clean_column(Second_data, 'art_tag', Special_character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Data Creation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Phase 1 :** Words list creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_list_of_words(list_tag: list) -> list:\n",
    "    \"\"\"Documentation\n",
    "    \n",
    "    Parameters :\n",
    "        - list_tag: list of all tag without the removal of unnecessary words\n",
    "        (for example : \"stopWords\") in the column [\"art_tag\"]\n",
    "\n",
    "    Output (if exists) :\n",
    "        - list_word: list of all the words in the tags \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # My initialized words list\n",
    "    list_word : list = []\n",
    "    \n",
    "    # Step 1 : route each tag\n",
    "    for tag in list_tag:\n",
    "        \n",
    "        # Step 2 : learn each words\n",
    "        for word in word_tokenize(tag):\n",
    "            \n",
    "            # Save the word not in\n",
    "            if (len(word) > 1) and \\\n",
    "                (word not in list_word):\n",
    "                \n",
    "                # My list saving word\n",
    "                list_word.append(word)\n",
    "    \n",
    "    # Return my list word\n",
    "    return list_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Phase 2 :** Dictionnary creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_dictionnary(list_tag: list, list_to_del: list = []) -> dict:\n",
    "    \"\"\"Documentation\n",
    "    \n",
    "    Parameters :\n",
    "        - list_tag: list of all tag without the removal of unnecessary words\n",
    "        (for example : \"stopWords\") in the column [\"art_tag\"]\n",
    "        - list_to_del: list of words that have a repetition greater than 10 in queries,\n",
    "          for which we don't recalculate the weight\n",
    "\n",
    "    Output (if exists) :\n",
    "        - dict_word: dictionnary of all words with their weight in the tags\n",
    "    \"\"\"\n",
    "    \n",
    "    # My initialized sum\n",
    "    total : int = 0\n",
    "    \n",
    "    # Call fonction for my list\n",
    "    list_word_unique : list = Create_list_of_words(list_tag)\n",
    "    \n",
    "    # Check the contents of the list\n",
    "    if list_to_del != []:\n",
    "        \n",
    "        # Step 1 : route each word\n",
    "        for elmt in list_to_del:\n",
    "            \n",
    "            # Remove duplicate word\n",
    "            del list_word_unique[list_word_unique.index(elmt)]\n",
    "    \n",
    "    # Create my word Dictionnary\n",
    "    dict_word : dict = {el: 0 for el in list_word_unique}\n",
    "    \n",
    "    # Tokenize all word\n",
    "    list_all_word : list = word_tokenize(' '.join(list_tag))\n",
    "    \n",
    "    # Step 2 : Dictionnary implement\n",
    "    for word in list_all_word:\n",
    "        \n",
    "        # Check word in my list\n",
    "        if word in list_word_unique:\n",
    "            \n",
    "            # Add to my dictionnary\n",
    "            dict_word[word] += 1\n",
    "    \n",
    "    # Step 3 : sum implement\n",
    "    for key, value in dict_word.items():\n",
    "        \n",
    "        # Add value to my sum\n",
    "        total += value\n",
    "    \n",
    "    # Step 4 : Dictionnary implement\n",
    "    for key, value in dict_word.items():\n",
    "        \n",
    "        # Add value to my dictionnary\n",
    "        dict_word[key] = value/total\n",
    "    \n",
    "    # Return my dictionnary\n",
    "    return dict_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 : Requests Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Phase 1 :** Initial requests list creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Description (To help understanding) :**  \n",
    "- We create a list of requests with random choice based on the words in the tags and without replace.\n",
    "\n",
    "- After this creation, we create requests based on the weight of the words in the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_requests(data: pd.DataFrame,\n",
    "                    nb_word: int,\n",
    "                    tag_only: bool = False,\n",
    "                    random: bool = False,\n",
    "                    weight: bool = False,\n",
    "                    nb_requests: int = 500) -> list:\n",
    "    \n",
    "    \"\"\"Documentation\n",
    "    \n",
    "    Parameters :\n",
    "        - data: dataframe containing tags clean\n",
    "        - nb_word: number of words we want in each request\n",
    "        - tag_only: True if we want to create random requests based on the tags\n",
    "        - random: True if we want to create random requests based on the words \n",
    "        in the tags and without replace,\n",
    "        - wheight: True if we want to create requests based on \n",
    "        the weight of the words in the tags\n",
    "        - nb_requests: number of requests we want for requests based on \n",
    "        the weight of the words in the tags\n",
    "\n",
    "    Output (if exists) :\n",
    "        - list_requests : list of requests\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # list of requests with tag\n",
    "    list_tag : pd.DataFrame  = data['clean'].unique().tolist()\n",
    "    \n",
    "    # Check condition\n",
    "    if tag_only:\n",
    "        \n",
    "        # My request variable\n",
    "        list_requests = list_tag\n",
    "\n",
    "    # create list of all the words in the tags\n",
    "    list_word_unique : list = Create_list_of_words(list_tag)\n",
    "\n",
    "    # Check condition\n",
    "    if random:\n",
    "        \n",
    "        # My initialized list\n",
    "        list_requests : list = []\n",
    "        \n",
    "        # Step 1 : check length condition\n",
    "        while len(list_word_unique) >= nb_word:\n",
    "            \n",
    "            # Choice a random list\n",
    "            temp : list = np.random.choice(list_word_unique, \\\n",
    "                                           nb_word, \\\n",
    "                                           replace=False)\n",
    "            \n",
    "            # Step 2 : check length condition\n",
    "            for elmt in temp:\n",
    "                \n",
    "                # Remove duplicate word\n",
    "                del list_word_unique[list_word_unique.index(elmt)]\n",
    "            \n",
    "            # Adding request list\n",
    "            temp = ' '.join(temp)\n",
    "            list_requests.append(temp)\n",
    "        \n",
    "        # Check condition\n",
    "        if list_word_unique != []:\n",
    "            \n",
    "            # Adding request list\n",
    "            list_requests.append(' '.join(list_word_unique))\n",
    "\n",
    "    # Check condition\n",
    "    if weight:\n",
    "        \n",
    "        # My initialized list\n",
    "        list_requests : list = []\n",
    "        \n",
    "        # My initialized list\n",
    "        words_to_del : list = []\n",
    "        \n",
    "        # Fonction application to create dictionnary\n",
    "        dict_word : dict = Create_dictionnary(list_tag)\n",
    "        \n",
    "        # New dictionnary for requests\n",
    "        dict_word_in_requests : dict = {el: 0 for el in list_word_unique}\n",
    "        \n",
    "        # Step 3 : check length condition\n",
    "        while (len(dict_word) >= nb_word) and \\\n",
    "                len(list_requests) < nb_requests:\n",
    "            \n",
    "            # Choice a new random list\n",
    "            temp = np.random.choice(list(dict_word.keys()), \n",
    "                                    nb_word, \n",
    "                                    replace = False, \n",
    "                                    p = list(dict_word.values()))\n",
    "            \n",
    "            # Step 4 : check all element in my list\n",
    "            for elmt in temp:\n",
    "                \n",
    "                # Add element to my dict\n",
    "                dict_word_in_requests[elmt] += 1\n",
    "                \n",
    "                # Check condition\n",
    "                if dict_word_in_requests[elmt] == 10:\n",
    "                    \n",
    "                    # Add my revome list\n",
    "                    words_to_del.append(elmt)\n",
    "                    \n",
    "                    # Fonction application to create last dictionnary\n",
    "                    dict_word = Create_dictionnary(list_tag, words_to_del)\n",
    "            \n",
    "            # Adding request list        \n",
    "            temp = ' '.join(temp)\n",
    "            list_requests.append(temp)\n",
    "    \n",
    "    # Return my completed requests list\n",
    "    return list_requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Phase 2 :** Keywords requests list creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_requests_keywords(list_keywords: list,\n",
    "                             nb_word: int,\n",
    "                             nb_words_repetition: int,\n",
    "                             Special_character: list) -> list:\n",
    "    \n",
    "    \"\"\"Documentation\n",
    "    \n",
    "    Parameters :\n",
    "        - list_keywords: list of keywords\n",
    "        - nb_word: number of words we want in each request\n",
    "        - nb_words_repetition: maximum number of repetitions of a word in queries\n",
    "\n",
    "    Output (if exists) :\n",
    "        - list_requests: my list of requests based to the keywords\n",
    "    \"\"\"\n",
    "\n",
    "    # My Keywords DataFrame\n",
    "    df_keywords : pd.DataFrame = pd.DataFrame(list_keywords, \\\n",
    "                                              columns=['keywords'])\n",
    "    \n",
    "    # My cleaned DataFrame\n",
    "    df_clean : pd.DataFrame = Clean_column(df_keywords, \\\n",
    "                                           'keywords', \\\n",
    "                                           Special_character)\n",
    "        \n",
    "    # My words list\n",
    "    list_word : list = df_clean['clean'].unique().tolist()\n",
    "    \n",
    "    # Initialized my requests list\n",
    "    list_requests : list = []\n",
    "    \n",
    "    # Create words dictionnary\n",
    "    dict_word_in_requests : dict = {el: 0 for el in list_word}\n",
    "    \n",
    "    # Step 1 : check length condition\n",
    "    while len(list_word) >= nb_word:\n",
    "        \n",
    "        # Choice a random list\n",
    "        temp = np.random.choice(list_word, nb_word, replace=False)\n",
    "        \n",
    "        # Step 2 : check all element in my list\n",
    "        for elmt in temp:\n",
    "            \n",
    "            # Add element to my dict\n",
    "            dict_word_in_requests[elmt] += 1\n",
    "            \n",
    "            # Check condition\n",
    "            if dict_word_in_requests[elmt] == nb_words_repetition:\n",
    "                \n",
    "                # Remove duplicate word\n",
    "                del list_word[list_word.index(elmt)]\n",
    "        \n",
    "        # Adding request list\n",
    "        temp = ' '.join(temp)\n",
    "        list_requests.append(temp)\n",
    "    \n",
    "    # Check condition\n",
    "    if list_word != []:\n",
    "        \n",
    "        # Adding request list\n",
    "        list_requests.append(' '.join(list_word))\n",
    "    \n",
    "    # Return my completed requests list\n",
    "    return list_requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6 : Requests Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 249/249 [00:00<00:00, 1323.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create my basics requests\n",
    "First_req_tag = Create_requests(First_df_tag, 7, tag_only = True)\n",
    "Second_req_tag = Create_requests(Second_df_tag, 7, tag_only = True)\n",
    "First_req_rand = Create_requests(First_df_tag, 7, random = True)\n",
    "Second_req_rand = Create_requests(Second_df_tag, 7, random = True)\n",
    "First_req_weight = Create_requests(First_df_tag, 7, weight = True, nb_requests = 1000)\n",
    "Second_req_weight = Create_requests(Second_df_tag, 7, weight = True)\n",
    "\n",
    "# Create my keywords request\n",
    "Request_keywords = Create_requests_keywords(List_keywords, 5, 10, Special_character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Optionnal Application :** print all requests to see the contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics Requests\n",
    "# print(request_tag[:10])\n",
    "# print(request_tag2[:10])\n",
    "# print(request_random_word[:10])\n",
    "# print(request_random_word2[:10])\n",
    "# print(request_word_weight[:10])\n",
    "# print(request_word_weight2[:10])\n",
    "\n",
    "# Keywords Requests\n",
    "# print(request_keywords[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7 : Requests list creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 249/249 [00:00<00:00, 1422.82it/s]\n"
     ]
    }
   ],
   "source": [
    "List_request = Create_requests_keywords(List_keywords, 5, 10, Special_character)\n",
    "List_request.extend(Create_requests(Second_df_tag, 7, weight=True))\n",
    "List_request.extend(Create_requests(First_df_tag, 7, weight=True, nb_requests=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8 : Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('list_queries_simulation', 'wb') as f1:\n",
    "    pickle.dump(List_request, f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
